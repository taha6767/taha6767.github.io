[
  {
    "objectID": "tidytuesday2.html",
    "href": "tidytuesday2.html",
    "title": "Draught Analysis of California",
    "section": "",
    "text": "The data is from the U.S. Drought Monitor. The tidytuesday github link is:\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-07-20/readme.md\n\n\n\n\n\n\n\n\n\n\nCalifornia experiences frequent fluctuations in drought conditions, with periods of severe drought interspersed with times of little to no drought.\nThe most severe and prolonged drought period occurred around 2014-2016, with a large portion of the state experiencing D3 and D4 (extreme to exceptional) drought levels.\nThere are notable cycles of drought intensification and relief, with conditions often improving rapidly before worsening again.\nThe early 2000s and the period around 2010 saw relatively milder drought conditions compared to the mid-2010s.\nTowards the end of the timeline (2020-2021), there’s an indication of drought conditions worsening again, suggesting a potentially developing drought situation."
  },
  {
    "objectID": "tidytuesday1.html",
    "href": "tidytuesday1.html",
    "title": "CEO departure analysis",
    "section": "",
    "text": "The data comes from Gentry et al. by way of DataIsPlural. It contains the reasons for CEO departure in S&P 1500 firms from 2000 through 2018.\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-04-27/readme.md\n\n\n\n\n\n\n\n\n\n\nRetirement is by far the most common reason for CEO departures, accounting for the highest number of cases.\n“Other” reasons form the second largest category, suggesting that many CEO departures are due to complex or unspecified factors.\nBad performance is the third most frequent reason, indicating that a significant number of CEOs leave their positions due to poor company results.\nLegal issues and new opportunities are the least common reasons for CEO departures, with relatively few cases in each category.\nThe data suggests that natural career progression (retirement) and unspecified factors play a larger role in CEO turnover than forced departures due to performance issues or legal troubles."
  },
  {
    "objectID": "Project2Taha copy.html",
    "href": "Project2Taha copy.html",
    "title": "taha6767.github.io",
    "section": "",
    "text": "Mustafa Taha Disbudak Project 1\n\n# Define our genres of interest which are the most well know genres\ngenres_of_interest &lt;- c(\n  \"crime\", \"thriller\", \n  \"comedy\", \n  \"drama\", \n  \"action\", \"adventure\",\n  \"romantic\", \"romance\",\n  \"science fiction\", \"sci-fi\", \"fantasy\",\n  \"documentary\",\n  \"horror\"\n)\n\n# Function to clean and split genres\nclean_genres &lt;- function(x) {\n  x |&gt;\n    str_split(\",\") |&gt;\n    unlist() |&gt;\n    str_trim() |&gt;\n    str_remove_all(\"(?i)movies|tv shows\") |&gt;\n    str_trim() |&gt;\n    str_to_lower()\n}\n\n# Analyze genres\ngenre_counts &lt;- netflix |&gt;\n  mutate(genres = map(listed_in, clean_genres)) |&gt;\n  unnest(genres) |&gt;\n  mutate(\n    genre_category = case_when(\n      str_detect(genres, \"(?i)crime|thriller\") ~ \"Crime/Thriller\",\n      str_detect(genres, \"(?i)comedy\") ~ \"Comedy\",\n      str_detect(genres, \"(?i)drama\") ~ \"Drama\",\n      str_detect(genres, \"(?i)action|adventure\") ~ \"Action & Adventure\",\n      str_detect(genres, \"(?i)romantic|romance\") ~ \"Romantic Comedies\",\n      str_detect(genres, \"(?i)science fiction|sci-fi|fantasy\") ~ \"Science Fiction & Fantasy\",\n      str_detect(genres, \"(?i)documentary\") ~ \"Documentary\",\n      str_detect(genres, \"(?i)horror\") ~ \"Horror\",\n      TRUE ~ \"Other\"\n    )\n  ) |&gt;\n  filter(genre_category != \"Other\") |&gt;\n  distinct(show_id, genre_category) |&gt;  # Count each title only once per category\n  count(genre_category, sort = TRUE)\n\n# Print results\nprint(genre_counts)\n\n# A tibble: 7 × 2\n  genre_category                n\n  &lt;chr&gt;                     &lt;int&gt;\n1 Drama                      2810\n2 Crime/Thriller              958\n3 Action & Adventure          871\n4 Romantic Comedies           864\n5 Comedy                      381\n6 Horror                      381\n7 Science Fiction & Fantasy   294\n\n# Calculate total titles\ntotal_titles &lt;- n_distinct(netflix$show_id)\nprint(paste(\"Total number of unique titles:\", total_titles))\n\n[1] \"Total number of unique titles: 7787\"\n\n# Calculate percentage for each genre\ngenre_counts &lt;- genre_counts |&gt;\n  mutate(percentage = n / total_titles * 100)\n\n# Print results with percentages\nprint(genre_counts)\n\n# A tibble: 7 × 3\n  genre_category                n percentage\n  &lt;chr&gt;                     &lt;int&gt;      &lt;dbl&gt;\n1 Drama                      2810      36.1 \n2 Crime/Thriller              958      12.3 \n3 Action & Adventure          871      11.2 \n4 Romantic Comedies           864      11.1 \n5 Comedy                      381       4.89\n6 Horror                      381       4.89\n7 Science Fiction & Fantasy   294       3.78\n\n# Create a bar plot for the genre distribution\nggplot(genre_counts, aes(x = reorder(genre_category, -n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"deeppink\") +\n  geom_text(aes(label = paste0(round(percentage, 1), \"%\")), vjust = -0.5) +\n  labs(\n    title = \"Comparison of Well Known Genres on Netflix\",\n    x = \"Genre\",\n    y = \"Number of Titles\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe graph illustrates the distribution of genres within Netflix’s library, highlighting a significant dominance of the drama genre, which accounts for over 36% of titles. This prevalence is understandable, as dramas often provide the foundation for captivating stories and frequently overlap with other genres, such as science fiction, romance, or thrillers. The substantial share of dramas suggests that Netflix prioritizes these versatile and emotionally engaging stories to attract a wide audience.\nIn addition to dramas, the Crime/Thriller and Action & Adventure genres also hold notable shares, each comprising around 12% of the content. These genres likely appeal to viewers seeking suspense and high-stakes plots, drawing consistent interest across various demographics. Furthermore, Romantic Comedies represent 11.1% of the library, catering to audiences looking for light-hearted, feel-good content.\nHorror genre hovers around only 5%. This is not surprising to me, as an horror fan I always have an hard time finding a good horror show on Netflix due to comparetavily limited options.\n\n# Extract and count actors\nactor_counts &lt;- netflix %&gt;%\n  mutate(actors = str_extract_all(cast, \"\\\\b[A-Z][a-z]+ [A-Z][a-z]+\\\\b\")) %&gt;%\n  unnest(actors) %&gt;%\n  count(actors, name = \"n\", sort = TRUE) %&gt;%  # Corrected the count function\n  slice_max(n, n = 10)  # Changed slice_top_n to slice_max\n\n# Plot top 10 actors\nggplot(actor_counts, aes(x = reorder(actors, n), y = n)) +\n  geom_col(fill = \"hotpink\") +\n  coord_flip() +\n  labs(title = \"Top 10 Most Frequently Cast Actors on Netflix\",\n       x = \"Actor\",\n       y = \"Number of Appearances\") +\n  theme_minimal() +\n  geom_text(aes(label = n), hjust = -0.2, size = 3)\n\n\n\n\n\n\n\n\nAccording to the graph the cast information was missing for 718 titles on Netflix which indicated the data we have is not of the highest quality. Anupam Kher is the most frequently cast actor on Netflix with 42 apperances.\n\n# Extract shows from Turkey\nturkish_shows &lt;- netflix %&gt;%\n  filter(str_detect(country, \"Turkey\")) %&gt;%\n  mutate(\n    year = as.integer(str_extract(date_added, \"\\\\d{4}\")),\n    type = type  \n  )\n\n# Analyze types of Turkish shows\nturkish_types &lt;- turkish_shows %&gt;%\n  count(type, sort = TRUE)\n\n# Plot distribution of Turkish show types\nggplot(turkish_types, aes(x = \"\", y = n, fill = type)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  labs(title = \"Distribution of Turkish Content on Netflix\",\n       fill = \"Type\") +\n  theme_void() +\n  geom_text(aes(label = paste0(type, \"\\n(\", n, \")\")), \n            position = position_stack(vjust = 0.5), \n            size = 4)  \n\n\n\n\n\n\n\n# Analyze trends in Turkish content over time\nturkish_trends &lt;- turkish_shows %&gt;%\n  count(year, type) %&gt;%\n  complete(year, type, fill = list(n = 0))\n\n# Plot trends in Turkish content\nggplot(turkish_trends, aes(x = year, y = n, color = type)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Trends in Turkish Content on Netflix\",\n       x = \"Year\",\n       y = \"Number of Titles\",\n       color = \"Type\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nMost titles from my home country Turkey have been movies which makes sense as TV Shows are much harder to produce. There is a substantial decrease in the movies and TV Shows coming from Turkey in 2018 this might be caused by:\nRegulatory and Political Issues: In 2018, Turkey introduced new regulations requiring streaming services to obtain licenses and comply with local broadcasting standards. This led to increased scrutiny and potential censorship, which might have affected the availability of Turkish content on platforms like Netflix1.\nContent Strategy Shifts: Netflix often adjusts its content strategy based on viewer preferences and market trends. Around that time, Netflix might have shifted its focus to other regions or types of content that were gaining more popularity globally2.\nProduction Challenges: Political and economic instability in Turkey during that period could have impacted the production and export of TV shows and movies. This might have led to fewer Turkish productions being available for international distribution2.\nDespite these challenges, Turkish content has seen a resurgence in recent years, with Netflix investing in new Turkish originals and licensing popular Turkish dramas3.\nReference: The data comes from the following TidyTuesday Github repository https://github.com/rfordatascience/tidytuesday/tree/master/data/2021/2021-04-20"
  },
  {
    "objectID": "Project3Taha.html",
    "href": "Project3Taha.html",
    "title": "Project3Taha",
    "section": "",
    "text": "Description of the Simulation Study\nThis simulation estimates the probability of having at least one close friend in one of your classes. You can adjust how many close friends you have, how many classes you are taking, how many people are there in each class and how many 5c students in total can potentially be taking the same classes with you. You can also adjust how many simulations you would like to run and in the end you get summary statistics and a bar graph.\nThrough random sampling with specific variables set at 12 close friends, 4 classes with 20 students each, and a total student population of 1500, the current set mimics my chances of getting a friend in the classes I will be taking next semester. 100,000 simulations are run to determine how likely it is for me to have close friends in different numbers of classes. For each simulation, it randomly assigns students to each class and checks if any of my close friends are present, then tallies how many classes contain at least one close friend. The results are visualized in a bar plot showing that I am most likely to have either no close friends in any class (52.2%) or close friends in just one class (36.8%), with the probability decreasing significantly for having close friends in multiple classes.\n\n# Load necessary libraries\n# Load necessary libraries quietly\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(scales))  # For better axis formatting\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Set simulation parameters\nnum_friends &lt;- 12           # Number of friends\nnum_classes &lt;- 4           # Number of classes taking\nclass_size &lt;- 20          # Number of people per class\ntotal_students &lt;- 1500    # Total students in Pomona classes\nnum_simulations &lt;- 100000  # Number of simulation runs\n\n# Define a function to simulate one scenario\nsimulate_friends_in_classes &lt;- function(num_friends, num_classes, class_size, total_students) {\n  # Generate friend IDs\n  friend_ids &lt;- sample(1:total_students, num_friends)\n  \n  # Simulate each class and count friends\n  class_results &lt;- map_lgl(1:num_classes, function(x) {\n    # Sample students for this class\n    class_students &lt;- sample(1:total_students, class_size)\n    # Check if any friends are in this class\n    any(friend_ids %in% class_students)\n  })\n  \n  # Return the number of classes with at least one friend\n  sum(class_results)\n}\n\n# Run multiple simulations using map_dbl\nresults &lt;- map_dbl(1:num_simulations, \n                  ~simulate_friends_in_classes(num_friends, num_classes, \n                                            class_size, total_students))\n\n# Create a data frame of results\nresults_df &lt;- tibble(\n  classes_with_friends = factor(results, levels = 0:num_classes),\n  count = 1\n) %&gt;%\n  group_by(classes_with_friends) %&gt;%\n  summarise(frequency = n()) %&gt;%\n  mutate(probability = frequency / num_simulations)\n\n# Create the visualization\nfriend_distribution_plot &lt;- ggplot(results_df, \n       aes(x = classes_with_friends, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", alpha = 0.8) +\n  geom_text(aes(label = paste0(scales::percent(probability, accuracy = 0.1),\n                              \"\\n(n=\", frequency, \")\")),\n            vjust = -0.5, size = 3.5) +\n  scale_y_continuous(labels = scales::percent, \n                    limits = c(0, max(results_df$probability) * 1.2)) +\n  labs(title = \"Distribution of Friends Across Classes\",\n       subtitle = paste(\"Based on\", num_simulations, \"simulations\"),\n       x = \"Number of Classes with at Least One Friend\",\n       y = \"Probability\",\n       caption = paste(\"Parameters:\", num_friends, \"friends,\", \n                      num_classes, \"classes,\", \n                      class_size, \"students per class\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\"),\n    panel.grid.major = element_line(color = \"gray90\"),\n    panel.grid.minor = element_line(color = \"gray95\")\n  )\n\n\n\n# Calculate summary statistics\nsummary_stats &lt;- list(\n  mean_classes = mean(results),\n  median_classes = median(results),\n  sd_classes = sd(results),\n  no_friends_count = sum(results == 0),\n  all_classes_count = sum(results == num_classes)\n)\n\n# Print summary statistics\ncat(\"\\nSummary Statistics:\\n\")\n\n\nSummary Statistics:\n\ncat(\"Mean number of classes with friends:\", round(summary_stats$mean_classes, 2), \"\\n\")\n\nMean number of classes with friends: 0.6 \n\ncat(\"Median number of classes with friends:\", summary_stats$median_classes, \"\\n\")\n\nMedian number of classes with friends: 0 \n\ncat(\"Standard deviation:\", round(summary_stats$sd_classes, 2), \"\\n\")\n\nStandard deviation: 0.72 \n\ncat(\"Number of simulations with no friends in any class:\", \n    summary_stats$no_friends_count, \"out of\", num_simulations, \"\\n\")\n\nNumber of simulations with no friends in any class: 52239 out of 1e+05 \n\ncat(\"Number of simulations with at least one friend in all classes:\", \n    summary_stats$all_classes_count, \"out of\", num_simulations, \"\\n\")\n\nNumber of simulations with at least one friend in all classes: 43 out of 1e+05 \n\n# Display the plot\nprint(friend_distribution_plot)\n\n\n\n\n\n\n\n\nThe bar plot shows the distribution of having close friends across different numbers of classes based on 100,000 simulations. The results reveal an interesting pattern: most commonly, students end up with either no close friends in any class (52.2% of simulations, occurring 52,239 times) or close friends in exactly one class (36.8% of simulations, occurring 36,777 times). The probability drops significantly for having close friends in two classes (9.7%, or 9,742 occurrences) and becomes quite rare for three classes (1.2%, or 1,199 occurrences). Having close friends in all four classes is extremely unlikely, occurring in only 43 out of 100,000 simulations (0.43%).\nThese results suggest that, given the parameters of 12 close friends, 4 classes of 20 students each, and a total population of 1,500 students, it’s most likely that you’ll either have no close friends in any of your classes or have close friends in just one class. The simulation indicates that having close friends spread across multiple classes becomes increasingly unlikely, with having close friends in all four classes being a very rare occurrence."
  },
  {
    "objectID": "TahaProject3Final.html",
    "href": "TahaProject3Final.html",
    "title": "Project3Taha",
    "section": "",
    "text": "Description of the Simulation Study\nThis simulation estimates the probability of having at least one close friend in one of your classes. You can adjust how many close friends you have, how many classes you are taking, how many people are there in each class and how many 5c students in total can potentially be taking the same classes with you. You can also adjust how many simulations you would like to run and in the end you get summary statistics and a bar graph.\nThrough random sampling with specific variables set at 12 close friends, 4 classes with 20 students each, and a total student population of 1500, the current set mimics my chances of getting a friend in the classes I will be taking next semester. 100,000 simulations are run to determine how likely it is for me to have close friends in different numbers of classes. For each simulation, it randomly assigns students to each class and checks if any of my close friends are present, then tallies how many classes contain at least one close friend. The results are visualized in a bar plot showing that I am most likely to have either no close friends in any class (52.2%) or close friends in just one class (36.8%), with the probability decreasing significantly for having close friends in multiple classes.\n\n# Load necessary libraries\n# Load necessary libraries quietly\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(scales))  # For better axis formatting\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Set simulation parameters\nnum_friends &lt;- 12           # Number of friends\nnum_classes &lt;- 4           # Number of classes taking\nclass_size &lt;- 20          # Number of people per class\ntotal_students &lt;- 1500    # Total students in Pomona classes\nnum_simulations &lt;- 100000  # Number of simulation runs\n\n# Define a function to simulate one scenario\nsimulate_friends_in_classes &lt;- function(num_friends, num_classes, class_size, total_students) {\n  # Generate friend IDs\n  friend_ids &lt;- sample(1:total_students, num_friends)\n  \n  # Simulate each class and count friends\n  class_results &lt;- map_lgl(1:num_classes, function(x) {\n    # Sample students for this class\n    class_students &lt;- sample(1:total_students, class_size)\n    # Check if any friends are in this class\n    any(friend_ids %in% class_students)\n  })\n  \n  # Return the number of classes with at least one friend\n  sum(class_results)\n}\n\n# Run multiple simulations using map_dbl\nresults &lt;- map_dbl(1:num_simulations, \n                  ~simulate_friends_in_classes(num_friends, num_classes, \n                                            class_size, total_students))\n\n# Create a data frame of results\nresults_df &lt;- tibble(\n  classes_with_friends = factor(results, levels = 0:num_classes),\n  count = 1\n) %&gt;%\n  group_by(classes_with_friends) %&gt;%\n  summarise(frequency = n()) %&gt;%\n  mutate(probability = frequency / num_simulations)\n\n# Create the visualization\nfriend_distribution_plot &lt;- ggplot(results_df, \n       aes(x = classes_with_friends, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", alpha = 0.8) +\n  geom_text(aes(label = paste0(scales::percent(probability, accuracy = 0.1),\n                              \"\\n(n=\", frequency, \")\")),\n            vjust = -0.5, size = 3.5) +\n  scale_y_continuous(labels = scales::percent, \n                    limits = c(0, max(results_df$probability) * 1.2)) +\n  labs(title = \"Distribution of Friends Across Classes\",\n       subtitle = paste(\"Based on\", num_simulations, \"simulations\"),\n       x = \"Number of Classes with at Least One Friend\",\n       y = \"Probability\",\n       caption = paste(\"Parameters:\", num_friends, \"friends,\", \n                      num_classes, \"classes,\", \n                      class_size, \"students per class\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\"),\n    panel.grid.major = element_line(color = \"gray90\"),\n    panel.grid.minor = element_line(color = \"gray95\")\n  )\n\n\n\n# Calculate summary statistics\nsummary_stats &lt;- list(\n  mean_classes = mean(results),\n  median_classes = median(results),\n  sd_classes = sd(results),\n  no_friends_count = sum(results == 0),\n  all_classes_count = sum(results == num_classes)\n)\n\n# Print summary statistics\ncat(\"\\nSummary Statistics:\\n\")\n\n\nSummary Statistics:\n\ncat(\"Mean number of classes with friends:\", round(summary_stats$mean_classes, 2), \"\\n\")\n\nMean number of classes with friends: 0.6 \n\ncat(\"Median number of classes with friends:\", summary_stats$median_classes, \"\\n\")\n\nMedian number of classes with friends: 0 \n\ncat(\"Standard deviation:\", round(summary_stats$sd_classes, 2), \"\\n\")\n\nStandard deviation: 0.72 \n\ncat(\"Number of simulations with no friends in any class:\", \n    summary_stats$no_friends_count, \"out of\", num_simulations, \"\\n\")\n\nNumber of simulations with no friends in any class: 52239 out of 1e+05 \n\ncat(\"Number of simulations with at least one friend in all classes:\", \n    summary_stats$all_classes_count, \"out of\", num_simulations, \"\\n\")\n\nNumber of simulations with at least one friend in all classes: 43 out of 1e+05 \n\n# Display the plot\nprint(friend_distribution_plot)\n\n\n\n\n\n\n\n\nThe bar plot shows the distribution of having close friends across different numbers of classes based on 100,000 simulations. The results reveal an interesting pattern: most commonly, students end up with either no close friends in any class (52.2% of simulations, occurring 52,239 times) or close friends in exactly one class (36.8% of simulations, occurring 36,777 times). The probability drops significantly for having close friends in two classes (9.7%, or 9,742 occurrences) and becomes quite rare for three classes (1.2%, or 1,199 occurrences). Having close friends in all four classes is extremely unlikely, occurring in only 43 out of 100,000 simulations (0.43%).\nThese results suggest that, given the parameters of 12 close friends, 4 classes of 20 students each, and a total population of 1,500 students, it’s most likely that you’ll either have no close friends in any of your classes or have close friends in just one class. The simulation indicates that having close friends spread across multiple classes becomes increasingly unlikely, with having close friends in all four classes being a very rare occurrence."
  },
  {
    "objectID": "Project4.html",
    "href": "Project4.html",
    "title": "Project 4",
    "section": "",
    "text": "library(mdsr)\nlibrary(dbplyr)\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(tidyverse)\n\nSource of Data: Wideband Acoustic Immittance (WAI) Database hosted by Smith College (doi.org/10.35482/egr.001.2022)\nPlan:\nIn this project, I plan to analyze and visualize data from the Wideband Acoustic Immittance (WAI) Database. To do so, I will consider the absorbance measurements across different frequencies for specific identifiers and groups. I will explore patterns in absorbance by using SQL queries, for instance, by grouping data by variables such as sex and frequency. Lastly, using ggplot, I intend to visualize the processed data in SQL to visually represent the explored relationships between variables.\n\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\n\n\n\n\n\nSELECT Identifier, Frequency, LOG10(Frequency) AS log_frequency, AVG(Absorbance) AS mean_absorbance \nFROM Measurements\nWHERE Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\" ,\"Lewis_2015\", \"Liu_2008\"\n\"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\" , \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\" ) AND Frequency &gt; 200 AND Frequency &lt; 8000\nGROUP BY Identifier, Frequency;\n\n\ngraph |&gt;\nggplot(aes (x = Frequency, y = mean_absorbance, \n  color = Identifier,\n  group = Identifier)) +\n  geom_line()+\n  scale_x_log10()\n\n\n\n\n\n\n\n  labs(\n    title = \"Mean Absorbance Across Frequencies for Various Studies\",\n    x = \"Frequency (Log Scale)\",\n    y = \"Mean Absorbance\"\n  )\n\n$x\n[1] \"Frequency (Log Scale)\"\n\n$y\n[1] \"Mean Absorbance\"\n\n$title\n[1] \"Mean Absorbance Across Frequencies for Various Studies\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nDescription of Graph:\nThis plot titled “Mean Absorbance Across Frequencies for Various Studies” shows the mean absorbance values across a range of frequencies (plotted on a log scale) for various studies, as identified by the color-coded legend. The graph, where each line represents data from a specific study, depicts how absorbance varies with frequency within the range of 200 to 8000. Overall, the absorbance increases with frequency, reaching a peak between approximately 1000 and 3000 before declining.\n\n SELECT p.Identifier, p.Year, p.AuthorsShortList, \n COUNT(DISTINCT SubjectNumber, Ear) AS ear_u\nFROM PI_Info AS p \nLEFT JOIN Measurements AS m ON m.Identifier = p.Identifier \nWHERE p.Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\" ,\"Lewis_2015\", \"Liu_2008\"\n\"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\" , \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\" ) AND Frequency &gt; 200 AND Frequency &lt; 8000\nGROUP BY Identifier, Instrument;\n\n\nDisplaying records 1 - 10\n\n\nIdentifier\nYear\nAuthorsShortList\near_u\n\n\n\n\nAbur_2014\n2014\nAbur et al.\n14\n\n\nFeeney_2017\n2017\nFeeney et al.\n57\n\n\nGroon_2015\n2015\nGroon et al.\n21\n\n\nLewis_2015\n2015\nLewis and Neely\n14\n\n\nShahnaz_2006\n2006\nShahnaz and Bork\n237\n\n\nShaver_2013\n2013\nShaver and Sun\n48\n\n\nSun_2016\n2016\nSun\n84\n\n\nVoss_1994\n1994\nVoss and Allen\n10\n\n\nVoss_2010\n2010\nVoss et al.\n12\n\n\nWerner_2010\n2010\nWerner et al.\n962\n\n\n\n\n\n\n SELECT p.Identifier, Year, AuthorsShortList, \n COUNT(DISTINCT SubjectNumber, Ear) AS ear_u,\n CONCAT(AuthorsShortList, \" (\" , year, \") \", \"N=\", COUNT(DISTINCT SubjectNumber, Ear), \"; \", Instrument) AS legend\nFROM PI_Info AS p \nLEFT JOIN Measurements AS m ON m.Identifier = p.Identifier \nWHERE p.Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\" ,\"Lewis_2015\", \"Liu_2008\"\n\"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\" , \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\" ) AND Frequency &gt; 200 AND Frequency &lt; 8000\nGROUP BY Identifier, Instrument;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\nIdentifier\nYear\nAuthorsShortList\near_u\nlegend\n\n\n\n\nAbur_2014\n2014\nAbur et al.\n14\nAbur et al. (2014) N=14; HearID\n\n\nFeeney_2017\n2017\nFeeney et al.\n57\nFeeney et al. (2017) N=57; preTitan\n\n\nGroon_2015\n2015\nGroon et al.\n21\nGroon et al. (2015) N=21; Other\n\n\nLewis_2015\n2015\nLewis and Neely\n14\nLewis and Neely (2015) N=14; Other\n\n\nShahnaz_2006\n2006\nShahnaz and Bork\n237\nShahnaz and Bork (2006) N=237; HearID\n\n\nShaver_2013\n2013\nShaver and Sun\n48\nShaver and Sun (2013) N=48; preTitan\n\n\nSun_2016\n2016\nSun\n84\nSun (2016) N=84; preTitan\n\n\nVoss_1994\n1994\nVoss and Allen\n10\nVoss and Allen (1994) N=10; preHearID\n\n\nVoss_2010\n2010\nVoss et al.\n12\nVoss et al. (2010) N=12; HearID\n\n\nWerner_2010\n2010\nWerner et al.\n962\nWerner et al. (2010) N=962; Other\n\n\n\n\n\n\n SELECT p.Identifier, p.Year, p.AuthorsShortList, Frequency,\n LOG10(Frequency) AS log_frequency, AVG(Absorbance) AS mean_absorbance,\n COUNT(DISTINCT SubjectNumber, Ear) AS ear_u,\n CONCAT(AuthorsShortList, \" (\" , year, \") \", \"N=\", COUNT(DISTINCT SubjectNumber, Ear), \"; \", Instrument) AS legend\nFROM PI_Info AS p \nLEFT JOIN Measurements AS m ON m.Identifier = p.Identifier \nWHERE p.Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\" ,\"Lewis_2015\", \"Liu_2008\"\n\"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\" , \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\" ) AND Frequency &gt; 200 AND Frequency &lt; 8000\nGROUP BY Identifier, Instrument, Frequency;\n\n\ngraph2 |&gt;\nggplot(aes (x = Frequency, y = mean_absorbance, \n  color = legend,\n  group = legend)) +\n  geom_line()+\n  scale_x_log10()\n\n\n\n\n\n\n\n\n\nSELECT * \nFROM Subjects\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSessionTotal\nAgeFirstMeasurement\nAgeCategoryFirstMeasurement\nSex\nRace\nEthnicity\nLeftEarStatusFirstMeasurement\nRightEarStatusFirstMeasurement\nSubjectNotes\n\n\n\n\nAbur_2014\n1\n7\n20.0000000\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n3\n8\n19.0000000\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\nSession 5 not included do to acoustic leak\n\n\nAbur_2014\n4\n7\n21.0000000\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n6\n8\n21.0000000\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n7\n5\n20.0000000\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n8\n5\n19.0000000\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n10\n5\n19.0000000\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\nSession 4 not included do to acoustic leak\n\n\nAithal_2013\n1\n1\nNA\nInfant\nMale\nUnknown\nUnknown\nNormal\nUnknown\nNA\n\n\nAithal_2013\n2\n1\n0.0074418\nInfant\nFemale\nUnknown\nUnknown\nNormal\nUnknown\nNA\n\n\nAithal_2013\n3\n1\nNA\nInfant\nMale\nUnknown\nUnknown\nUnknown\nNormal\nNA\n\n\n\n\n\n\nSELECT Sex, Frequency, \n    AVG(Absorbance) AS mean_absorbance, m.Identifier\nFROM Subjects AS s\nRIGHT JOIN Measurements AS m ON m.Identifier = s.Identifier \nWHERE m.Identifier = \"Lewis_2015\" AND Frequency &gt; 200 AND Frequency &lt; 8000\nGROUP BY m.Identifier, Frequency, Sex;\n\n\nhead(graphforQ2)\n\n     Sex Frequency mean_absorbance Identifier\n1 Female   205.078       0.2497826 Lewis_2015\n2 Male     205.078       0.2497826 Lewis_2015\n3 Female   210.938       0.2555734 Lewis_2015\n4 Male     210.938       0.2555734 Lewis_2015\n5 Female   216.797       0.2612649 Lewis_2015\n6 Male     216.797       0.2612649 Lewis_2015\n\n\n\ngraphforQ2 |&gt;\n  filter(Sex == \"Female\") |&gt;\nggplot(aes (x = Frequency, y = mean_absorbance, \n   color =  Sex,\n   group = Sex)) +\n  geom_line() +\n  scale_x_log10()\n\n\n\n\n\n\n\n  labs(\n    title = \"Mean Absorbance Across Frequencies for Females\",\n    x = \"Frequency (Log Scale)\",\n    y = \"Mean Absorbance\"\n  )\n\n$x\n[1] \"Frequency (Log Scale)\"\n\n$y\n[1] \"Mean Absorbance\"\n\n$title\n[1] \"Mean Absorbance Across Frequencies for Females\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nDescription of Plot:\nThis plot displays the mean absorbance across a range of frequencies (plotted on a log scale) for female participants. The red line represents how the absorbance changes as frequency increases, starting from around 300 and extending up to approximately 8000. Absorbance increases steadily at lower frequencies, reaching a peak between 1000 and 3000 before declining at higher frequencies.\nDescription of Code:\nIn the code above, I, initially, connected to the WAI database and used SQL queries to extract absorbance data grouped by identifiers, sex, and frequency, applying necessary filters for frequency range and study identifiers. Then, piping in the processed data into R, I visualized it via ggplot. For example, I plotted mean absorbance by frequency on a log scale, distinguishing data by attributes like sex or study identifiers."
  },
  {
    "objectID": "Project4Taha.html",
    "href": "Project4Taha.html",
    "title": "Project 4",
    "section": "",
    "text": "library(mdsr)\nlibrary(dbplyr)\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(tidyverse)\n\nSource of Data: Wideband Acoustic Immittance (WAI) Database hosted by Smith College (doi.org/10.35482/egr.001.2022)\n\nPlan\nIn this project, I analyze and visualize data from the WAI Database.\n\nFor Part 1, I replicate Figure 1 from Voss (2020) by querying the database to compute mean absorbance values across frequencies for 12 studies. The data is grouped and processed in SQL, and only visualization is performed in R using ggplot.\nFor Part 2, I investigate the absorbance behavior across different age groups (Child, Adult) within the Aithal_2019a study. I compute mean absorbance values by frequency and age group using SQL and plot these trends in R.\n\nRecreating figure 1:\n\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\n\nSELECT \n    m.Identifier, \n    m.Frequency, \n    AVG(m.Absorbance) AS mean_absorbance,\n    p.Year,\n    p.AuthorsShortList,\n    m.Instrument,\n    CONCAT(p.AuthorsShortList, ' (', p.Year, ') N=', \n           COUNT(DISTINCT CONCAT(m.SubjectNumber, m.Ear)), '; ', m.Instrument) AS legend\nFROM Measurements m\nINNER JOIN PI_Info p ON m.Identifier = p.Identifier\nWHERE m.Identifier IN (\n    'Abur_2014', 'Feeney_2017', 'Groon_2015', 'Lewis_2015', 'Liu_2008',\n    'Rosowski_2012', 'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n    'Voss_1994', 'Voss_2010', 'Werner_2010'\n) \nAND m.Frequency BETWEEN 200 AND 8000\nGROUP BY m.Identifier, m.Frequency, m.Instrument, p.Year, p.AuthorsShortList\n\n\ngraph |&gt;\nggplot(aes (x = Frequency, y = mean_absorbance, \n  color = Identifier,\n  group = Identifier)) +\n  geom_line()+\n  scale_x_log10()\n\n\n\n\n\n\n\n  labs(\n    title = \"Mean Absorbance Across Frequencies for Various Studies\",\n    x = \"Frequency (Log Scale)\",\n    y = \"Mean Absorbance\"\n  )\n\n$x\n[1] \"Frequency (Log Scale)\"\n\n$y\n[1] \"Mean Absorbance\"\n\n$title\n[1] \"Mean Absorbance Across Frequencies for Various Studies\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nThis visualization shows data from 12 different studies examining mean absorbance patterns across sound frequencies. Each study is represented by a uniquely colored line, with frequencies shown on a logarithmic scale from about 300 to 8000 Hz. Most studies follow a similar pattern: starting with low absorbance values (around 0.1-0.2) at lower frequencies, gradually increasing to reach maximum absorbance (between 0.6-0.8) in the mid-frequency range of 1000-3000 Hz, and then declining at higher frequencies. Notable variations exist between studies, particularly in the Feeney_2017 data which shows a distinctly different pattern with lower absorbance values and a delayed peak compared to other studies. The Lewis_2015 study shows the earliest rise in absorbance at low frequencies, while Werner_2010 achieves the highest peak absorbance values around 0.8.\nPart 2:\n\nSELECT \n    m.AgeCategory,\n    m.Frequency, \n    AVG(m.Absorbance) AS mean_absorbance,\n    m.Identifier\nFROM Measurements m\nINNER JOIN Subjects s ON m.Identifier = s.Identifier \n    AND m.SubjectNumber = s.SubjectNumber\nINNER JOIN PI_Info p ON m.Identifier = p.Identifier\nWHERE m.Identifier = 'Aithal_2019a' \n    AND m.Frequency BETWEEN 200 AND 8000\n    AND m.AgeCategory IS NOT NULL\nGROUP BY m.Identifier, m.Frequency, m.AgeCategory;\n\n\ngraphforQ2_comparison |&gt;\nggplot(aes(x = Frequency, y = mean_absorbance, \n   color = AgeCategory,\n   group = AgeCategory)) +\n  geom_line() +\n  scale_x_log10() +\n  labs(\n    title = \"Mean Absorbance Across Frequencies by Age Category\",\n    subtitle = \"Comparison between Children and Adults in Aithal 2019 Study\",\n    x = \"Frequency (Log Scale)\",\n    y = \"Mean Absorbance\",\n    color = \"Age Category\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis comparison of absorbance patterns between children and adults in the Aithal 2019 study reveals distinct age-related differences in auditory response. While adults show higher initial absorbance at lower frequencies (around 300 Hz), children demonstrate notably higher peak absorbance (reaching 0.7 compared to adults’ 0.55) in the mid-frequency range of 1000-3000 Hz. This pattern reverses at higher frequencies above 3500 Hz, where adults maintain slightly higher absorbance levels. These variations in absorbance patterns likely reflect the anatomical and developmental differences between children’s and adults’ auditory systems."
  }
]